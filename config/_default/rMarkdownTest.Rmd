---
output:
  html_document:
    theme: readable
    highlight: tango
    toc: true
    number_sections: false
    toc_depth: 2
    toc_float:
      collapsed: true
      smooth_scroll: true
editor_options: 
  chunk_output_type: inline
---
# HS650 Homework GIT HUB TEST

# Problem 1.1
**Long-to-Wide Data format translation**

## Download the data 

- Load the `rvest` web scraping package. 
```{r message=FALSE, warning=FALSE}
# install.packages('rvest')
library(rvest)
```

- Download the [SOCR Parkinson's Disease data](http://wiki.socr.umich.edu/index.php/SOCR_Data_PD_BiomedBigMetadata)
- Save the downloaded data as a data frame named **pd_data**. 
```{r}
wiki_url <- read_html('http://wiki.socr.umich.edu/index.php/SOCR_Data_PD_BiomedBigMetadata')

pd_data <- html_table(html_nodes(wiki_url, "table")[[1]])
```

- Check data to make sure it downloaded correctly. 
```{r}
str(pd_data)
head(pd_data)
```

## Choose 3 variables

I will make a short data frame using the following 3 variables, in addition to the case and time variables, for ease of handling:

- *Case* refers to case subject identifier 
- *Time* refers to visit time with four time-points: (baseline (0), 6, 12, and 18 month follow-ups).
- *L_caudate_volume* refers to the the 3D volume/size of the left caudate 
- *Weight* refers to weight in kg
- *Age* refers to age in years

```{r}
# create short data frame with relevant variables for ease of handling
pd_data_short <- data.frame(pd_data$Cases,
                            pd_data$Time,
                            pd_data$L_caudate_Volume, 
                            pd_data$Weight, 
                            pd_data$Age)
```

- Take out 'pd_data.' from the column names.
```{r}
names(pd_data_short) = sub("pd_data.","",names(pd_data_short))   
```

- Check **pd_data_short** data frame.
```{r}
pd_data_short
```

## Translate data from long-to-wide format

- I used the `reshape` function in the `stats` package to translate the data from long-to-wide. 
- After transforming from long to wide, now there is a column for each case of *L_caudate_volume*, *Weight*, and *Age* at each measurement visit occasion, corresponding to baseline/0, 6 months, 12 months, and 18 months. 

```{r}
library(stats)

pd_data_wide <- reshape(pd_data_short, 
                        idvar = "Cases", 
                        timevar = "Time", 
                        direction = "wide")
head(pd_data_wide)
```


# Problem 1.2
**Data stratification**

## Preprocessing
- For this problem, I will be using the same the [SOCR Parkinson's Disease data](http://wiki.socr.umich.edu/index.php/SOCR_Data_PD_BiomedBigMetadata) as in the first problem. 
- However, I will only be extracting the rows where *Time* = 0 (e.g. measurements taken at baseline). This new data frame will be named **pd_data_baseline**.
```{r}
pd_data_baseline <- pd_data[pd_data$Time == 0,]   # extract rows where Time = 0
```

- Check to make sure **pd_data_baseline** has been processed correctly by looking at how many rows of *Time* = 0 are in the original data set, **pd_data** and in the new data set **pd_data_baseline**.  
- It's 282 in both, so we're in the clear.
```{r}
nrow(pd_data_baseline)

table(pd_data$Time) 
```

## First 10 subjects 
- Select the first 10 subjects from **pd_data_baseline**. 
```{r}
pd_data_baseline_first10 <- pd_data_baseline[1:10,]

pd_data_baseline_first10
```

## L_caudate_ComputeArea < 600
- Using the `tidyverse` package, I found cases for which *L_caudate_ComputeArea* < 600. 
```{r warning=FALSE}
library(tidyverse)

pd_data_baseline_LCCA_Under_600 <- pd_data_baseline %>% 
  filter(L_caudate_ComputeArea < 600)

pd_data_baseline_LCCA_Under_600
```

## Sort L_caudate_Volume 
- Sort the subjects based on *L_caudate_Volume* in ascending order 
```{r include = TRUE}
ascending <- pd_data_baseline[order(pd_data_baseline$L_caudate_Volume),]
head(ascending)
```

- Sort the subjects based on *L_caudate_Volume* in descending order.
```{r}
descending <- pd_data_baseline[order(-pd_data_baseline$L_caudate_Volume),] 
head(descending)
```

## Generate frequency and probability tables for Age and Sex.
- Using the `gmodels` package, I generated a cross table for *Age* which includes frequencies and probabilities in decimal form within each cell. 
```{r}
# install.packages('gmodels')
library(gmodels)
CrossTable(pd_data_baseline$Age)
```

- Using the `gmodels` package, I generated a cross table for *Sex* which includes frequencies and probabilities in decimal form within each cell. 
```{r}
library(gmodels)
CrossTable(pd_data_baseline$Sex)
```

## Compute the mean Age and the correlation between Age and Weight.
- Compute the mean for *Age*. 
```{r}
mean(pd_data_baseline$Age, na.rm = TRUE)
```

- Find the correlation between *Age* and *Weight*. 
```{r}
pd_data_baseline %>% 
  select(Weight, Age) %>% 
  cor()
```

## Plotting Histogram, Density, and Scatterplot
- Plot histogram of *R_fusiform_gyrus_Volume*. 
```{r}
hist(pd_data_baseline$R_fusiform_gyrus_Volume,
     col = "yellow",
     border = "blue",
     main = "Histogram of R_fusiform_gyrus_Volume",
     xlab = "R_fusiform_gyrus_Volume")
```

- Plot density of *R_fusiform_gyrus_Volume* 
```{r}
library(lattice)
densityplot(pd_data_baseline$R_fusiform_gyrus_Volume,
            col = "blue",
            main = "Density Plot of R_fusiform_gyrus_Volume",
            xlab = "R_fusiform_gyrus_Volume")
```

- Plot scatterplot *L_fusiform_gyrus_Volume* and *R_fusiform_gyrus_Volume*.
```{r}
plot(pd_data_baseline$L_fusiform_gyrus_Volume, pd_data_baseline$R_fusiform_gyrus_Volume,
     type = "p",
            main = "Scatterplot of L_fusiform_gyrus_Volume and R_fusiform_gyrus_Volume",
            xlab = "L_fusiform_gyrus_Volume",
            ylab = "R_fusiform_gyrus_Volume")
```

# Problem 1.3 
**Simulation**

## Generate variables

- Generate 1,000 standard normal variables using `rnorm` function.
```{r}
normal_dist <- rnorm(1000, mean=0, sd=1)
hist(normal_dist,
     main = "Histogram Standard Normal Distribution, N = 1000",
     xlab = "Values", 
     xlim = range(-4,4))
```

- Generate 1,200 student t distributed random variables with df=20 using `rt` function.
```{r}
studentt_dist <- rt(1200, 20)
hist(studentt_dist,
     main = "Histogram of Student T Distribution, N=1200, df = 20",
     xlab = "Values",
     xlim = range(-4,4))
```

## Quantile-Quantile Plot
- Generate a quantile-quantile (Q-Q) probability plot of the two samples.
```{r}
qqplot(normal_dist, studentt_dist, 
                main="Q-Q Probability Plot", 
                xlab="Normal Distribution", 
                ylab="Student T Distribution")
```

- Compare with qqnorm of student t simulation.
```{r}
qqnorm(studentt_dist, 
                main="Q-Q Probability Plot", 
                xlab="Theoretical Quantiles of the Student T Distribution", 
                ylab="Sample Quantiles of Student T Distribution Data")
    qqline(studentt_dist)
```

# Problem 1.4
**Define an R SD function**

- Generate a function that computes a sample standard deviation function.
```{r}
standard_deviation <- function(x) {
  
    v <- sum( (x - mean(x) )^2 )
    n <- length(x)-1
    if(n > 0) {
      sqrt(v/n)
    }
    else {
      warning("CANNOT COMPUTE SD. PLEASE CHECK YOUR INPUT VALUES.")
    }
    
}
```

- Compare it against the `sd` function using the simulation data you generate in the last question.
```{r}
standard_deviation(normal_dist)
sd(normal_dist)

standard_deviation(studentt_dist)
sd(studentt_dist)
```

- Did you cover all situations?
```{r}
x <- c(0)
standard_deviation(x)
```

